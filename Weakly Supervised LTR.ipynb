{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1005aaa5",
   "metadata": {},
   "source": [
    "# Using Weak Supervision to Generate Book Recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5eea19a",
   "metadata": {},
   "source": [
    "### by Vinayak Siva Kumar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d82632e3",
   "metadata": {},
   "source": [
    "We will use a books dataset to collect several user ratings and generate ratings of the books based on book ids that the users have interacted with, using weak supervision."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e5d78a1",
   "metadata": {},
   "source": [
    "## Loading Books Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd03045e",
   "metadata": {},
   "source": [
    "Dataset credit to Mengting Wan, Julian McAuley, \"Item Recommendation on Monotonic Behavior Chains\", in RecSys'18.  &\n",
    "Mengting Wan, Rishabh Misra, Ndapa Nakashole, Julian McAuley, \"Fine-Grained Spoiler Detection from Large-Scale Review Corpora\", in ACL'19.\n",
    "\n",
    "We have a set of users and books, and for each user we know the set of books they have interacted with (read or marked as to-read). We don't have the user's numerical ratings for the books they read, except in a small number of cases. We also have some text reviews written by users.\n",
    "\n",
    "This recommendation engine would be able to recommend books to a user when they visit the site that visits this site. For example, we can just predict the rating for the user paired with a book for a few thousand likely books, then pick the books with the top ten predicted ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0bcf0f52",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vinay\\Documents\\Weakly Supervision\\data.py:225: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_interactions_nz[\"rating_4_5\"] = df_interactions_nz.rating.map(ratings_map)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>authors</th>\n",
       "      <th>average_rating</th>\n",
       "      <th>book_id</th>\n",
       "      <th>country_code</th>\n",
       "      <th>description</th>\n",
       "      <th>is_ebook</th>\n",
       "      <th>language_code</th>\n",
       "      <th>ratings_count</th>\n",
       "      <th>similar_books</th>\n",
       "      <th>text_reviews_count</th>\n",
       "      <th>title</th>\n",
       "      <th>first_author</th>\n",
       "      <th>book_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[293603]</td>\n",
       "      <td>4.35</td>\n",
       "      <td>10099492</td>\n",
       "      <td>US</td>\n",
       "      <td>It all comes down to this.\\nVlad's running out...</td>\n",
       "      <td>True</td>\n",
       "      <td>eng</td>\n",
       "      <td>152</td>\n",
       "      <td>[25861113, 7430195, 18765937, 6120544, 3247550...</td>\n",
       "      <td>9</td>\n",
       "      <td>Twelfth Grade Kills (The Chronicles of Vladimi...</td>\n",
       "      <td>293603</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[4018722]</td>\n",
       "      <td>3.71</td>\n",
       "      <td>22642971</td>\n",
       "      <td>US</td>\n",
       "      <td>The future world is at peace.\\nElla Shepherd h...</td>\n",
       "      <td>True</td>\n",
       "      <td>eng</td>\n",
       "      <td>1525</td>\n",
       "      <td>[20499652, 17934493, 13518102, 16210411, 17149...</td>\n",
       "      <td>428</td>\n",
       "      <td>The Body Electric</td>\n",
       "      <td>4018722</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[6537142]</td>\n",
       "      <td>3.89</td>\n",
       "      <td>31556136</td>\n",
       "      <td>US</td>\n",
       "      <td>A gorgeously written and deeply felt literary ...</td>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "      <td>109</td>\n",
       "      <td>[]</td>\n",
       "      <td>45</td>\n",
       "      <td>Like Water</td>\n",
       "      <td>6537142</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[6455200, 5227552]</td>\n",
       "      <td>3.90</td>\n",
       "      <td>18522274</td>\n",
       "      <td>US</td>\n",
       "      <td>Zoe Vanderveen is on the run with her captor t...</td>\n",
       "      <td>True</td>\n",
       "      <td>en-US</td>\n",
       "      <td>191</td>\n",
       "      <td>[25063023, 18553080, 17567752, 18126509, 17997...</td>\n",
       "      <td>6</td>\n",
       "      <td>Volition (The Perception Trilogy, #2)</td>\n",
       "      <td>6455200</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[187837]</td>\n",
       "      <td>3.19</td>\n",
       "      <td>17262776</td>\n",
       "      <td>US</td>\n",
       "      <td>The war is over, but for thirteen-year-old Rac...</td>\n",
       "      <td>True</td>\n",
       "      <td>eng</td>\n",
       "      <td>248</td>\n",
       "      <td>[16153997, 10836616, 17262238, 16074827, 13628...</td>\n",
       "      <td>68</td>\n",
       "      <td>Little Red Lies</td>\n",
       "      <td>187837</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               authors  average_rating   book_id country_code  \\\n",
       "3             [293603]            4.35  10099492           US   \n",
       "4            [4018722]            3.71  22642971           US   \n",
       "5            [6537142]            3.89  31556136           US   \n",
       "12  [6455200, 5227552]            3.90  18522274           US   \n",
       "13            [187837]            3.19  17262776           US   \n",
       "\n",
       "                                          description  is_ebook language_code  \\\n",
       "3   It all comes down to this.\\nVlad's running out...      True           eng   \n",
       "4   The future world is at peace.\\nElla Shepherd h...      True           eng   \n",
       "5   A gorgeously written and deeply felt literary ...      True                 \n",
       "12  Zoe Vanderveen is on the run with her captor t...      True         en-US   \n",
       "13  The war is over, but for thirteen-year-old Rac...      True           eng   \n",
       "\n",
       "    ratings_count                                      similar_books  \\\n",
       "3             152  [25861113, 7430195, 18765937, 6120544, 3247550...   \n",
       "4            1525  [20499652, 17934493, 13518102, 16210411, 17149...   \n",
       "5             109                                                 []   \n",
       "12            191  [25063023, 18553080, 17567752, 18126509, 17997...   \n",
       "13            248  [16153997, 10836616, 17262238, 16074827, 13628...   \n",
       "\n",
       "    text_reviews_count                                              title  \\\n",
       "3                    9  Twelfth Grade Kills (The Chronicles of Vladimi...   \n",
       "4                  428                                  The Body Electric   \n",
       "5                   45                                         Like Water   \n",
       "12                   6              Volition (The Perception Trilogy, #2)   \n",
       "13                  68                                    Little Red Lies   \n",
       "\n",
       "    first_author  book_idx  \n",
       "3         293603         0  \n",
       "4        4018722         1  \n",
       "5        6537142         2  \n",
       "12       6455200         3  \n",
       "13        187837         4  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from data import download_and_process_data\n",
    "\n",
    "(df_train, df_test, df_dev, df_valid), df_books = download_and_process_data()\n",
    "\n",
    "df_books.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb13f6bd",
   "metadata": {},
   "source": [
    "Important Features we will extract/make:\n",
    "- user_idx: A unique identifier for a user.\n",
    "- book_idx: A unique identifier for a book that is being rated by the user.\n",
    "- book_idxs: The set of books that the user has interacted with (read or planned to read).\n",
    "- review_text: Optional text review written by the user for the book.\n",
    "- rating: Either 0 (which means the user did not read or did not like the book) or 1 (which means the user read and liked the book). The rating field is missing for df_train. We will be generating this \"weak\" label "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dbc38c1",
   "metadata": {},
   "source": [
    "## Creating Weak Labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "963a5480",
   "metadata": {},
   "source": [
    "If a user has interacted with several books written by an author, there is a good chance that the user will read and like other books by the same author. We express this as a labeling function, using the first_author field in the df_books dataframe. We use 15 books as a treshold for this though. We also  write a simple LF that looks for similar phrases to guess the user's rating of a book. We interpret >= 4 stars to indicate a positive rating, while < 4 stars is negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2680f6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Labels to occupy the ratings column\n",
    "POSTIVE = 1\n",
    "NEGATIVE = 0\n",
    "ABSTAIN = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4cd4ff85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.labeling.lf import labeling_function\n",
    "\n",
    "book_to_first_author = dict(zip(df_books.book_idx, df_books.first_author))\n",
    "first_author_to_books_df = df_books.groupby(\"first_author\")[[\"book_idx\"]].agg(set)\n",
    "first_author_to_books = dict(\n",
    "    zip(first_author_to_books_df.index, first_author_to_books_df.book_idx)\n",
    ")\n",
    "\n",
    "\n",
    "@labeling_function(\n",
    "    resources=dict(\n",
    "        book_to_first_author=book_to_first_author,\n",
    "        first_author_to_books=first_author_to_books,\n",
    "    )\n",
    ")\n",
    "def shared_first_author(x, book_to_first_author, first_author_to_books):\n",
    "    author = book_to_first_author[x.book_idx]\n",
    "    same_author_books = first_author_to_books[author]\n",
    "    num_read = len(set(x.book_idxs).intersection(same_author_books))\n",
    "    return POSITIVE if num_read > 15 else ABSTAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9a1ad407",
   "metadata": {},
   "outputs": [],
   "source": [
    "low_rating_strs = [\n",
    "    \"one star\",\n",
    "    \"1 star\",\n",
    "    \"two star\",\n",
    "    \"2 star\",\n",
    "    \"3 star\",\n",
    "    \"three star\",\n",
    "    \"3.5 star\",\n",
    "    \"2.5 star\",\n",
    "    \"1 out of 5\",\n",
    "    \"2 out of 5\",\n",
    "    \"3 out of 5\",\n",
    "]\n",
    "high_rating_strs = [\"5 stars\", \"five stars\", \"four stars\", \"4 stars\", \"4.5 stars\"]\n",
    "\n",
    "\n",
    "@labeling_function(\n",
    "    resources=dict(low_rating_strs=low_rating_strs, high_rating_strs=high_rating_strs)\n",
    ")\n",
    "def stars_in_review(x, low_rating_strs, high_rating_strs):\n",
    "    if not isinstance(x.review_text, str):\n",
    "        return ABSTAIN\n",
    "    for low_rating_str in low_rating_strs:\n",
    "        if low_rating_str in x.review_text.lower():\n",
    "            return NEGATIVE\n",
    "    for high_rating_str in high_rating_strs:\n",
    "        if high_rating_str in x.review_text.lower():\n",
    "            return POSITIVE\n",
    "    return ABSTAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c60f4c10",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\snorkel\\lib\\site-packages\\sklearn\\feature_extraction\\image.py:167: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  dtype=np.int):\n",
      "C:\\ProgramData\\Anaconda3\\envs\\snorkel\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:30: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  method='lar', copy_X=True, eps=np.finfo(np.float).eps,\n",
      "C:\\ProgramData\\Anaconda3\\envs\\snorkel\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:167: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  method='lar', copy_X=True, eps=np.finfo(np.float).eps,\n",
      "C:\\ProgramData\\Anaconda3\\envs\\snorkel\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:284: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_Gram=True, verbose=0,\n",
      "C:\\ProgramData\\Anaconda3\\envs\\snorkel\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:862: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_X=True, fit_path=True,\n",
      "C:\\ProgramData\\Anaconda3\\envs\\snorkel\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:1101: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_X=True, fit_path=True,\n",
      "C:\\ProgramData\\Anaconda3\\envs\\snorkel\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:1127: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, positive=False):\n",
      "C:\\ProgramData\\Anaconda3\\envs\\snorkel\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:1362: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  max_n_alphas=1000, n_jobs=None, eps=np.finfo(np.float).eps,\n",
      "C:\\ProgramData\\Anaconda3\\envs\\snorkel\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:1602: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  max_n_alphas=1000, n_jobs=None, eps=np.finfo(np.float).eps,\n",
      "C:\\ProgramData\\Anaconda3\\envs\\snorkel\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:1738: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_X=True, positive=False):\n"
     ]
    }
   ],
   "source": [
    "from snorkel.preprocess import preprocessor\n",
    "from textblob import TextBlob\n",
    "\n",
    "\n",
    "@preprocessor(memoize=True)\n",
    "def textblob_polarity(x):\n",
    "    if isinstance(x.review_text, str):\n",
    "        x.blob = TextBlob(x.review_text)\n",
    "    else:\n",
    "        x.blob = None\n",
    "    return x\n",
    "\n",
    "\n",
    "# Label high polarity reviews as positive.\n",
    "@labeling_function(pre=[textblob_polarity])\n",
    "def polarity_positive(x):\n",
    "    if x.blob:\n",
    "        if x.blob.polarity > 0.3:\n",
    "            return POSITIVE\n",
    "    return ABSTAIN\n",
    "\n",
    "\n",
    "# Label high subjectivity reviews as positive.\n",
    "@labeling_function(pre=[textblob_polarity])\n",
    "def subjectivity_positive(x):\n",
    "    if x.blob:\n",
    "        if x.blob.subjectivity > 0.75:\n",
    "            return POSITIVE\n",
    "    return ABSTAIN\n",
    "\n",
    "\n",
    "# Label low polarity reviews as negative.\n",
    "@labeling_function(pre=[textblob_polarity])\n",
    "def polarity_negative(x):\n",
    "    if x.blob:\n",
    "        if x.blob.polarity < 0.0:\n",
    "            return NEGATIVE\n",
    "    return ABSTAIN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b231f1",
   "metadata": {},
   "source": [
    "We run TextBlob, a tool that provides a pretrained sentiment analyzer, on the reviews, and use its polarity and subjectivity scores to estimate the user's rating for the book. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "32dff025",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8267/8267 [00:04<00:00, 1655.49it/s]\n"
     ]
    }
   ],
   "source": [
    "from snorkel.labeling import PandasLFApplier, LFAnalysis\n",
    "\n",
    "lfs = [\n",
    "    stars_in_review,\n",
    "    shared_first_author,\n",
    "    polarity_positive,\n",
    "    subjectivity_positive,\n",
    "    polarity_negative,\n",
    "]\n",
    "\n",
    "applier = PandasLFApplier(lfs)\n",
    "L_dev = applier.apply(df_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "280f68a8",
   "metadata": {},
   "source": [
    "## Attach the pseudo-labels to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "00a54d30",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 795540/795540 [08:01<00:00, 1653.15it/s]\n"
     ]
    }
   ],
   "source": [
    "from snorkel.labeling.model import LabelModel\n",
    "\n",
    "L_train = applier.apply(df_train)\n",
    "label_model = LabelModel(cardinality=2, verbose=True)\n",
    "label_model.fit(L_train, n_epochs=5000, seed=123, log_freq=20, lr=0.01)\n",
    "preds_train = label_model.predict(L_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2fe2e232",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\snorkel\\lib\\site-packages\\ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "from snorkel.labeling import filter_unlabeled_dataframe\n",
    "\n",
    "df_train_filtered, preds_train_filtered = filter_unlabeled_dataframe(\n",
    "    df_train, preds_train, L_train\n",
    ")\n",
    "df_train_filtered[\"rating\"] = preds_train_filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d0333e",
   "metadata": {},
   "source": [
    "## Designing The Neural Network Prediction Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d59c6601",
   "metadata": {},
   "source": [
    "We write a Tensorflow-Keras model for predicting ratings given a user's book list and a book (which is being rated). The model represents the list of books the user interacted with, books_idxs, by learning an embedding for each idx, and averaging the embeddings in book_idxs. It learns another embedding for the book_idx, the book to be rated. Then it concatenates the two embeddings and uses an MLP network to compute the probability of the rating being 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "76d403a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from data import precision_batch, recall_batch, f1_batch\n",
    "\n",
    "n_books = max([max(df.book_idx) for df in [df_train, df_test, df_dev, df_valid]])\n",
    "\n",
    "\n",
    "# Keras model to predict rating given book_idxs and book_idx.\n",
    "def get_model(embed_dim=64, hidden_layer_sizes=[32]):\n",
    "    # Compute embedding for book_idxs.\n",
    "    len_book_idxs = tf.keras.layers.Input([])\n",
    "    book_idxs = tf.keras.layers.Input([None])\n",
    "    # book_idxs % n_books is to prevent crashing if a book_idx in book_idxs is > n_books.\n",
    "    book_idxs_emb = tf.keras.layers.Embedding(n_books, embed_dim)(book_idxs % n_books)\n",
    "    book_idxs_emb = tf.math.divide(\n",
    "        tf.keras.backend.sum(book_idxs_emb, axis=1), tf.expand_dims(len_book_idxs, 1)\n",
    "    )\n",
    "    # Compute embedding for book_idx.\n",
    "    book_idx = tf.keras.layers.Input([])\n",
    "    book_idx_emb = tf.keras.layers.Embedding(n_books, embed_dim)(book_idx)\n",
    "    input_layer = tf.keras.layers.concatenate([book_idxs_emb, book_idx_emb], 1)\n",
    "    # Build MLP on input layer.\n",
    "    cur_layer = input_layer\n",
    "    for size in hidden_layer_sizes:\n",
    "        tf.keras.layers.Dense(size, activation=tf.nn.relu)(cur_layer)\n",
    "    output_layer = tf.keras.layers.Dense(1, activation=tf.nn.sigmoid)(cur_layer)\n",
    "    # Create and compile keras model.\n",
    "    model = tf.keras.Model(\n",
    "        inputs=[len_book_idxs, book_idxs, book_idx], outputs=[output_layer]\n",
    "    )\n",
    "    model.compile(\n",
    "        \"Adagrad\",\n",
    "        \"binary_crossentropy\",\n",
    "        metrics=[\"accuracy\", precision_batch, recall_batch,ndcg_score],\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "71b00a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator to turn dataframe into data points.\n",
    "def get_data_points_generator(df):\n",
    "    def generator():\n",
    "        for book_idxs, book_idx, rating in zip(df.book_idxs, df.book_idx, df.rating):\n",
    "            # Remove book_idx from book_idxs so the model can't just look it up.\n",
    "            book_idxs = tuple(filter(lambda x: x != book_idx, book_idxs))\n",
    "            yield {\n",
    "                \"len_book_idxs\": len(book_idxs),\n",
    "                \"book_idxs\": book_idxs,\n",
    "                \"book_idx\": book_idx,\n",
    "                \"label\": rating,\n",
    "            }\n",
    "            if rating == 1:\n",
    "                # Generate a random negative book_id not in book_idxs.\n",
    "                random_negative = np.random.randint(0, n_books)\n",
    "                while random_negative in book_idxs:\n",
    "                    random_negative = np.random.randint(0, n_books)\n",
    "                yield {\n",
    "                    \"len_book_idxs\": len(book_idxs),\n",
    "                    \"book_idxs\": book_idxs,\n",
    "                    \"book_idx\": random_negative,\n",
    "                    \"label\": 0,\n",
    "                }\n",
    "\n",
    "    return generator\n",
    "\n",
    "\n",
    "def get_data_tensors(df):\n",
    "    # Use generator to get data points each epoch, along with shuffling and batching.\n",
    "    padded_shapes = {\n",
    "        \"len_book_idxs\": [],\n",
    "        \"book_idxs\": [None],\n",
    "        \"book_idx\": [],\n",
    "        \"label\": [],\n",
    "    }\n",
    "    dataset = (\n",
    "        tf.data.Dataset.from_generator(\n",
    "            get_data_points_generator(df), {k: tf.int64 for k in padded_shapes}\n",
    "        )\n",
    "        .shuffle(123)\n",
    "        .repeat(None)\n",
    "        .padded_batch(batch_size=256, padded_shapes=padded_shapes)\n",
    "    )\n",
    "    tensor_dict = tf.compat.v1.data.make_one_shot_iterator(dataset).get_next()\n",
    "    return (\n",
    "        (\n",
    "            tensor_dict[\"len_book_idxs\"],\n",
    "            tensor_dict[\"book_idxs\"],\n",
    "            tensor_dict[\"book_idx\"],\n",
    "        ),\n",
    "        tensor_dict[\"label\"],\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5755b90",
   "metadata": {},
   "source": [
    "## Training The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f4f9d437",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "300/300 [==============================] - 1s 1ms/step - loss: 0.6925 - accuracy: 0.5033 - precision_batch: 0.2933 - recall_batch: 0.2933 - val_loss: 0.6914 - val_accuracy: 0.5742 - val_precision_batch: 0.4982 - val_recall_batch: 0.5246\n",
      "Epoch 2/30\n",
      "300/300 [==============================] - 0s 781us/step - loss: 0.6912 - accuracy: 0.5500 - precision_batch: 0.1833 - recall_batch: 0.1833 - val_loss: 0.6913 - val_accuracy: 0.5781 - val_precision_batch: 0.4995 - val_recall_batch: 0.5091\n",
      "Epoch 3/30\n",
      "300/300 [==============================] - 0s 704us/step - loss: 0.6895 - accuracy: 0.6300 - precision_batch: 0.2233 - recall_batch: 0.2233 - val_loss: 0.6913 - val_accuracy: 0.5781 - val_precision_batch: 0.4995 - val_recall_batch: 0.5091\n",
      "Epoch 4/30\n",
      "300/300 [==============================] - 0s 708us/step - loss: 0.6897 - accuracy: 0.5900 - precision_batch: 0.1800 - recall_batch: 0.1800 - val_loss: 0.6912 - val_accuracy: 0.5742 - val_precision_batch: 0.4981 - val_recall_batch: 0.5036\n",
      "Epoch 5/30\n",
      "300/300 [==============================] - 0s 708us/step - loss: 0.6878 - accuracy: 0.6333 - precision_batch: 0.1667 - recall_batch: 0.1667 - val_loss: 0.6911 - val_accuracy: 0.5859 - val_precision_batch: 0.5188 - val_recall_batch: 0.4846\n",
      "Epoch 6/30\n",
      "300/300 [==============================] - 0s 705us/step - loss: 0.6867 - accuracy: 0.6300 - precision_batch: 0.1267 - recall_batch: 0.1267 - val_loss: 0.6911 - val_accuracy: 0.5898 - val_precision_batch: 0.5245 - val_recall_batch: 0.4596\n",
      "Epoch 7/30\n",
      "300/300 [==============================] - 0s 703us/step - loss: 0.6865 - accuracy: 0.6300 - precision_batch: 0.1333 - recall_batch: 0.1333 - val_loss: 0.6911 - val_accuracy: 0.5898 - val_precision_batch: 0.5245 - val_recall_batch: 0.4596\n",
      "Epoch 8/30\n",
      "300/300 [==============================] - 0s 730us/step - loss: 0.6851 - accuracy: 0.6667 - precision_batch: 0.1433 - recall_batch: 0.1433 - val_loss: 0.6910 - val_accuracy: 0.5859 - val_precision_batch: 0.5349 - val_recall_batch: 0.4270\n",
      "Epoch 9/30\n",
      "300/300 [==============================] - 0s 804us/step - loss: 0.6847 - accuracy: 0.6367 - precision_batch: 0.1433 - recall_batch: 0.1433 - val_loss: 0.6910 - val_accuracy: 0.5820 - val_precision_batch: 0.5324 - val_recall_batch: 0.4187\n",
      "Epoch 10/30\n",
      "300/300 [==============================] - 0s 696us/step - loss: 0.6843 - accuracy: 0.6433 - precision_batch: 0.1367 - recall_batch: 0.1367 - val_loss: 0.6909 - val_accuracy: 0.5781 - val_precision_batch: 0.5249 - val_recall_batch: 0.4187\n",
      "Epoch 11/30\n",
      "300/300 [==============================] - 0s 712us/step - loss: 0.6832 - accuracy: 0.6400 - precision_batch: 0.1167 - recall_batch: 0.1167 - val_loss: 0.6909 - val_accuracy: 0.5820 - val_precision_batch: 0.5324 - val_recall_batch: 0.4187\n",
      "Epoch 12/30\n",
      "300/300 [==============================] - 0s 686us/step - loss: 0.6819 - accuracy: 0.6833 - precision_batch: 0.1367 - recall_batch: 0.1367 - val_loss: 0.6909 - val_accuracy: 0.5781 - val_precision_batch: 0.5240 - val_recall_batch: 0.4087\n",
      "Epoch 13/30\n",
      "300/300 [==============================] - 0s 692us/step - loss: 0.6817 - accuracy: 0.6700 - precision_batch: 0.1433 - recall_batch: 0.1433 - val_loss: 0.6908 - val_accuracy: 0.5820 - val_precision_batch: 0.5261 - val_recall_batch: 0.3987\n",
      "Epoch 14/30\n",
      "300/300 [==============================] - 0s 706us/step - loss: 0.6816 - accuracy: 0.6700 - precision_batch: 0.1367 - recall_batch: 0.1367 - val_loss: 0.6908 - val_accuracy: 0.5781 - val_precision_batch: 0.5211 - val_recall_batch: 0.3987\n",
      "Epoch 15/30\n",
      "300/300 [==============================] - 0s 730us/step - loss: 0.6795 - accuracy: 0.7033 - precision_batch: 0.1433 - recall_batch: 0.1433 - val_loss: 0.6908 - val_accuracy: 0.5820 - val_precision_batch: 0.5261 - val_recall_batch: 0.3931\n",
      "Epoch 16/30\n",
      "300/300 [==============================] - 0s 706us/step - loss: 0.6792 - accuracy: 0.6867 - precision_batch: 0.1400 - recall_batch: 0.1400 - val_loss: 0.6908 - val_accuracy: 0.5938 - val_precision_batch: 0.5588 - val_recall_batch: 0.3931\n",
      "Epoch 17/30\n",
      "300/300 [==============================] - 0s 697us/step - loss: 0.6789 - accuracy: 0.7100 - precision_batch: 0.1600 - recall_batch: 0.1600 - val_loss: 0.6907 - val_accuracy: 0.5938 - val_precision_batch: 0.5588 - val_recall_batch: 0.3931\n",
      "Epoch 18/30\n",
      "300/300 [==============================] - 0s 705us/step - loss: 0.6780 - accuracy: 0.6967 - precision_batch: 0.1500 - recall_batch: 0.1500 - val_loss: 0.6907 - val_accuracy: 0.5938 - val_precision_batch: 0.5588 - val_recall_batch: 0.3931\n",
      "Epoch 19/30\n",
      "300/300 [==============================] - 0s 703us/step - loss: 0.6772 - accuracy: 0.7100 - precision_batch: 0.1500 - recall_batch: 0.1500 - val_loss: 0.6907 - val_accuracy: 0.5938 - val_precision_batch: 0.5588 - val_recall_batch: 0.3931\n",
      "Epoch 20/30\n",
      "300/300 [==============================] - 0s 695us/step - loss: 0.6778 - accuracy: 0.6933 - precision_batch: 0.1667 - recall_batch: 0.1667 - val_loss: 0.6907 - val_accuracy: 0.5898 - val_precision_batch: 0.5538 - val_recall_batch: 0.3931\n",
      "Epoch 21/30\n",
      "300/300 [==============================] - 0s 697us/step - loss: 0.6756 - accuracy: 0.7200 - precision_batch: 0.1567 - recall_batch: 0.1567 - val_loss: 0.6906 - val_accuracy: 0.5977 - val_precision_batch: 0.5671 - val_recall_batch: 0.3931\n",
      "Epoch 22/30\n",
      "300/300 [==============================] - 0s 710us/step - loss: 0.6743 - accuracy: 0.7267 - precision_batch: 0.1733 - recall_batch: 0.1733 - val_loss: 0.6906 - val_accuracy: 0.5938 - val_precision_batch: 0.5630 - val_recall_batch: 0.3860\n",
      "Epoch 23/30\n",
      "300/300 [==============================] - 0s 705us/step - loss: 0.6751 - accuracy: 0.7067 - precision_batch: 0.1600 - recall_batch: 0.1600 - val_loss: 0.6906 - val_accuracy: 0.5938 - val_precision_batch: 0.5780 - val_recall_batch: 0.3776\n",
      "Epoch 24/30\n",
      "300/300 [==============================] - 0s 710us/step - loss: 0.6730 - accuracy: 0.7200 - precision_batch: 0.1433 - recall_batch: 0.1433 - val_loss: 0.6906 - val_accuracy: 0.5898 - val_precision_batch: 0.5780 - val_recall_batch: 0.3714\n",
      "Epoch 25/30\n",
      "300/300 [==============================] - 0s 685us/step - loss: 0.6736 - accuracy: 0.7300 - precision_batch: 0.1800 - recall_batch: 0.1800 - val_loss: 0.6905 - val_accuracy: 0.5898 - val_precision_batch: 0.5780 - val_recall_batch: 0.3714\n",
      "Epoch 26/30\n",
      "165/300 [===============>..............] - ETA: 0s - loss: 0.6725 - accuracy: 0.7152 - precision_batch: 0.1636 - recall_batch: 0.1636       WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 9000 batches). You may need to use the repeat() function when building your dataset.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 9000 batches). You may need to use the repeat() function when building your dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "300/300 [==============================] - 0s 528us/step - loss: 0.6724 - accuracy: 0.7278 - precision_batch: 0.1667 - recall_batch: 0.1667 - val_loss: 0.6905 - val_accuracy: 0.5859 - val_precision_batch: 0.5613 - val_recall_batch: 0.3642\n"
     ]
    }
   ],
   "source": [
    "from data import get_n_epochs\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "model = get_model()\n",
    "\n",
    "X_train, Y_train = get_data_tensors(df_train_filtered)\n",
    "X_valid, Y_valid = get_data_tensors(df_valid)\n",
    "train_model=model.fit(\n",
    "    X_train,\n",
    "    Y_train,\n",
    "    steps_per_epoch=300,\n",
    "    validation_data=(X_valid, Y_valid),\n",
    "    validation_steps=20,\n",
    "    epochs=get_n_epochs(),\n",
    "    verbose=1,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ce877cc6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x17c46a66048>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss = train_model.history['loss']\n",
    "val_loss = train_model.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(loss) + 1)\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f29621d3",
   "metadata": {},
   "source": [
    "## Testing the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "35a6485c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 1ms/step - loss: 0.6873 - accuracy: 0.6484 - precision_batch: 0.3006 - recall_batch: 0.1889\n"
     ]
    }
   ],
   "source": [
    "X_test, Y_test = get_data_tensors(df_test)\n",
    "test_results = model.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "f2cc2d51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is  0.6484\n",
      "Precision Score is  0.3006\n",
      "Recall Score is  0.1889\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy is \",round(test_results[1],4))\n",
    "print(\"Precision Score is \",round(test_results[2],4))\n",
    "print(\"Recall Score is \",round(test_results[3],4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:snorkel]",
   "language": "python",
   "name": "conda-env-snorkel-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
